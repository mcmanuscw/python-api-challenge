{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeatherPy\n",
    "----\n",
    "\n",
    "#### Note\n",
    "* Instructions have been included for each segment. You do not have to follow them exactly, but they are included to help you think through the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from scipy.stats import linregress\n",
    "# Import API key\n",
    "from api_keys import weather_api_key\n",
    "\n",
    "# Incorporated citipy to determine city based on latitude and longitude\n",
    "        # using this to generate the list of cities  below\n",
    "from citipy import citipy\n",
    "\n",
    "# Output File (CSV)\n",
    "output_data_file = \"cities.csv\"\n",
    "\n",
    "# Range of latitudes and longitudes\n",
    "lat_range = (-90, 90)\n",
    "lng_range = (-180, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output_data/cities.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Janssen VR 2\\Documents\\GitHub\\python-api-challenge\\WeatherPy.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Janssen%20VR%202/Documents/GitHub/python-api-challenge/WeatherPy.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#CSV into DF\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Janssen%20VR%202/Documents/GitHub/python-api-challenge/WeatherPy.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cities_info \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(output_data_file)\n",
      "File \u001b[1;32mc:\\BootCamp\\envs\\PythonData\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\BootCamp\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\BootCamp\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\BootCamp\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\BootCamp\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\BootCamp\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output_data/cities.csv'"
     ]
    }
   ],
   "source": [
    "#CSV into DF\n",
    "cities_info = pd.read_csv(output_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Cities List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lists and variables for holding lat_lngs and cities\n",
    "lat_lngs = []\n",
    "cities = []\n",
    "\n",
    "# Create a set of random lat and lng combinations\n",
    "lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)\n",
    "lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)\n",
    "lat_lngs = zip(lats, lngs)\n",
    "\n",
    "# Identify nearest city for each lat, lng combination\n",
    "for lat_lng in lat_lngs:\n",
    "    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name\n",
    "    \n",
    "    # If the city is unique, then add it to a our cities list\n",
    "    if city not in cities:\n",
    "        cities.append(city)\n",
    "\n",
    "# Print the city count to confirm sufficient count\n",
    "len(cities)\n",
    "\n",
    "# #for testing we are going to use a smaller set of names; drop this once the code is good\n",
    "# cities = [\"Paris\", \"London\", \"Oslo\", \"Beijing\", \"Mumbai\", \"Manila\", \"New York\", \"Seattle\", \"Dallas\", \"Taipei\"]\n",
    "\n",
    "# # Print the city count to confirm sufficient count\n",
    "len(cities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform API Calls\n",
    "* Perform a weather check on each city using a series of successive API calls.\n",
    "* Include a print log of each city as it'sbeing processed (with the city number and city name).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://api.openweathermap.org/data/2.5/weather?appid=2126a8dfc46686055d87f1210e58a355&q=Wayne&units=Imperial\n"
     ]
    }
   ],
   "source": [
    "#Home 40.0416, 75.3699\n",
    "\n",
    "# Save config information from  https://openweathermap.org/current#data\n",
    "# Save config information\n",
    "base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "units = \"Imperial\" #metric\n",
    "#  city = \"New York\" # for testing\n",
    "\n",
    "# Build query URL\n",
    "mod_url = base_url + \"appid=\" + weather_api_key + \"&units=\" + units + \"&q=\" + city\n",
    "mod_url\n",
    "\n",
    "\n",
    "# Call weather data using api\n",
    "#initialize lists to store attributes from csv file in preparation for API calls\n",
    "city_name = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "temp = []\n",
    "humidity = []\n",
    "cloudiness = []\n",
    "wind_speed = []\n",
    "country = []\n",
    "date = []\n",
    "\n",
    "# initialize counters for looping through the cities data\n",
    "counter = 0\n",
    "set_counter = 1\n",
    "next_counter = 0\n",
    "skip_counter = 0\n",
    "\n",
    "print(mod_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data captured for ['Paris'] ([2988507])\n",
      "Data captured for ['Paris', 'London'] ([2988507, 2643743])\n",
      "Data captured for ['Paris', 'London', 'Oslo'] ([2988507, 2643743, 3143244])\n",
      "Data captured for ['Paris', 'London', 'Oslo', 'Beijing'] ([2988507, 2643743, 3143244, 1816670])\n",
      "Data captured for ['Paris', 'London', 'Oslo', 'Beijing', 'Mumbai'] ([2988507, 2643743, 3143244, 1816670, 1275339])\n",
      "Data captured for ['Paris', 'London', 'Oslo', 'Beijing', 'Mumbai', 'Manila'] ([2988507, 2643743, 3143244, 1816670, 1275339, 1701668])\n",
      "Data captured for ['Paris', 'London', 'Oslo', 'Beijing', 'Mumbai', 'Manila', 'New York'] ([2988507, 2643743, 3143244, 1816670, 1275339, 1701668, 5128581])\n",
      "Data captured for ['Paris', 'London', 'Oslo', 'Beijing', 'Mumbai', 'Manila', 'New York', 'Seattle'] ([2988507, 2643743, 3143244, 1816670, 1275339, 1701668, 5128581, 5809844])\n",
      "Data captured for ['Paris', 'London', 'Oslo', 'Beijing', 'Mumbai', 'Manila', 'New York', 'Seattle', 'Dallas'] ([2988507, 2643743, 3143244, 1816670, 1275339, 1701668, 5128581, 5809844, 4684904])\n",
      "Data captured for ['Paris', 'London', 'Oslo', 'Beijing', 'Mumbai', 'Manila', 'New York', 'Seattle', 'Dallas', 'Taipei'] ([2988507, 2643743, 3143244, 1816670, 1275339, 1701668, 5128581, 5809844, 4684904, 1668341])\n"
     ]
    }
   ],
   "source": [
    "# From Lesson\n",
    "\n",
    "cities = [\"Paris\", \"London\", \"Oslo\", \"Beijing\", \"Mumbai\", \"Manila\", \"New York\", \"Seattle\", \"Dallas\", \"Taipei\"]\n",
    "\n",
    "# set up lists to hold reponse info\n",
    "city_name = []\n",
    "city_number = []\n",
    "lat = []\n",
    "lon = []\n",
    "temp = []\n",
    "humidity = []\n",
    "wind = []\n",
    "clouds = []\n",
    "country = []\n",
    "date = []\n",
    "\n",
    "# Loop through the list of cities and perform a request for data on each\n",
    "for city in cities:\n",
    "    response = requests.get(query_url + city).json()\n",
    "    city_number.append(response['id'])\n",
    "    city_name.append(response['name'])\n",
    "    lat.append(response['coord']['lat'])\n",
    "    lon.append(response['coord']['lon'])\n",
    "    temp.append(response['main']['temp'])\n",
    "    wind.append(response['wind']['speed'])\n",
    "    clouds.append(response[\"clouds\"][\"all\"])\n",
    "    humidity.append(response[\"main\"][\"humidity\"])\n",
    "    \n",
    "    print(f\"Data captured for {city_name} ({city_number})\")\n",
    "\n",
    "\n",
    "# print(f\"The city number info received are: {city_number}\")\n",
    "# print(f\"The city name info received is: {city_name}\")\n",
    "# print(f\"The latitude info received is: {lat}\")\n",
    "# print(f\"The longitude info received is: {lon}\")\n",
    "# print(f\"The temperature info received is: {temp}\")\n",
    "# print(f\"The humidity info received is: {humidity}\")\n",
    "# print(f\"The wind info received is: {wind}\")\n",
    "# print(f\"The clouds info received is: {clouds}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"base\": \"stations\",\n",
      "    \"clouds\": {\n",
      "        \"all\": 0\n",
      "    },\n",
      "    \"cod\": 200,\n",
      "    \"coord\": {\n",
      "        \"lat\": 25.0478,\n",
      "        \"lon\": 121.5319\n",
      "    },\n",
      "    \"dt\": 1660236524,\n",
      "    \"id\": 1668341,\n",
      "    \"main\": {\n",
      "        \"feels_like\": 92.82,\n",
      "        \"humidity\": 74,\n",
      "        \"pressure\": 1009,\n",
      "        \"temp\": 84.42,\n",
      "        \"temp_max\": 87.03,\n",
      "        \"temp_min\": 82.56\n",
      "    },\n",
      "    \"name\": \"Taipei\",\n",
      "    \"sys\": {\n",
      "        \"country\": \"TW\",\n",
      "        \"id\": 266033,\n",
      "        \"sunrise\": 1660253178,\n",
      "        \"sunset\": 1660300311,\n",
      "        \"type\": 2\n",
      "    },\n",
      "    \"timezone\": 28800,\n",
      "    \"visibility\": 10000,\n",
      "    \"weather\": [\n",
      "        {\n",
      "            \"description\": \"clear sky\",\n",
      "            \"icon\": \"01n\",\n",
      "            \"id\": 800,\n",
      "            \"main\": \"Clear\"\n",
      "        }\n",
      "    ],\n",
      "    \"wind\": {\n",
      "        \"deg\": 230,\n",
      "        \"gust\": 8.01,\n",
      "        \"speed\": 4\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = (json.dumps(response, indent=5, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a new data frame with the columns\n",
    "cities_df = pd.DataFrame(columns=['cities'])\n",
    "    \n",
    "cities_df['cities'] = cities\n",
    "\n",
    "cities_df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Raw Data to DataFrame\n",
    "* Export the city data into a .csv.\n",
    "* Display the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data and remove the cities where the humidity > 100%.\n",
    "----\n",
    "Skip this step if there are no cities that have humidity > 100%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get the indices of cities that have humidity over 100%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new DataFrame equal to the city data to drop all humidity outliers by index.\n",
    "# Passing \"inplace=False\" will make a copy of the city_data DataFrame, which we call \"clean_city_data\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data\n",
    "* Use proper labeling of the plots using plot titles (including date of analysis) and axes labels.\n",
    "* Save the plotted figures as .pngs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Temperature Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Humidity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Cloudiness Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Wind Speed Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Northern Hemisphere - Max Temp vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Southern Hemisphere - Max Temp vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Northern Hemisphere - Humidity (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Southern Hemisphere - Humidity (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Northern Hemisphere - Cloudiness (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Southern Hemisphere - Cloudiness (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Northern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Southern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "28fbf62663af58e83c120b24022b22a4bf7ae7e3f21e1dcc78d79bfe2dce8aef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
